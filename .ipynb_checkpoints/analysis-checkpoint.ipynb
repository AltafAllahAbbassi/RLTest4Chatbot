{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk.corpus as wordnet \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(result_file):\n",
    "    ## returns \n",
    "    f = open(result_file)\n",
    "    rewards = []\n",
    "    joint_accs= []\n",
    "    trans_rates = []\n",
    "\n",
    "    rewards_ = []\n",
    "    joint_accs_ = []\n",
    "    trans_rates_ = []\n",
    "    results = json.load(f)\n",
    "    for dialogue_r in results : \n",
    "        reward = []\n",
    "        joint_acc = []\n",
    "        trans_rate = []\n",
    "        for turn_r in dialogue_r[\"dialogue\"]:\n",
    "            trans_rate.append(turn_r[\"transformation_rate\"])\n",
    "            reward.append(turn_r[\"reward\"])\n",
    "            joint_acc.append(turn_r[\"joint_acc\"])\n",
    "        rewards.append(reward)\n",
    "        trans_rates.append(trans_rate)\n",
    "        joint_accs.append(joint_acc)\n",
    "\n",
    "        rewards_.extend(reward)\n",
    "        trans_rates_.extend(trans_rate)\n",
    "        joint_accs_.extend(joint_acc)\n",
    "    f.close()\n",
    "\n",
    "    return rewards_, joint_accs_, trans_rates_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(result_file):\n",
    "    f = open(result_file)\n",
    "    results = json.load(f)\n",
    "    tran = []\n",
    "    trans_tr = []\n",
    "    trans_rates = []\n",
    "    n_trans_rates = []\n",
    "    for dialogue_r in results : \n",
    "        for turn_r in dialogue_r[\"dialogue\"]:\n",
    "            tran.append(turn_r[\"transcript\"])\n",
    "            trans_tr.append(turn_r[\"transcript_tran\"])\n",
    "            trans_rates.append(turn_r[\"transformation_rate\"])\n",
    "            xx = 1-calculate_similarity(turn_r[\"transcript\"],turn_r[\"transcript_tran\"])\n",
    "            n_trans_rates.append(xx)\n",
    "\n",
    "           \n",
    "    f.close()\n",
    "\n",
    "    return tran, trans_tr, trans_rates, n_trans_rates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _synset_similarity(s1,s2):\n",
    "    L1 =dict()\n",
    "    L2 =defaultdict(list)\n",
    "       \n",
    "    for syn1 in s1:\n",
    "        L1[syn1[0]] =list()\n",
    "        for syn2 in s2:                                     \n",
    "            \n",
    "            subsumer = syn1[1].lowest_common_hypernyms(syn2[1], simulate_root=True)[0]\n",
    "            h =subsumer.max_depth() + 1 # as done on NLTK wordnet        \n",
    "            syn1_dist_subsumer = syn1[1].shortest_path_distance(subsumer,simulate_root =True)\n",
    "            syn2_dist_subsumer = syn2[1].shortest_path_distance(subsumer,simulate_root =True)\n",
    "            l  =syn1_dist_subsumer + syn2_dist_subsumer\n",
    "            f1 = np.exp(-alpha*l)\n",
    "            a  = np.exp(beta*h)\n",
    "            b  = np.exp(-beta*h)\n",
    "            f2 = (a-b) /(a+b)\n",
    "            sim = f1*f2\n",
    "            L1[syn1[0]].append(sim)          \n",
    "            L2[syn2[0]].append(sim)\n",
    "    return L1, L2     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5709/2025564678.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_tr1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_rates1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trans_rates1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_1.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_tr2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_rates2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trans_rates2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_2.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_tr3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_rates3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trans_rates3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_3.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_tr4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_rates4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trans_rates4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_4.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtran\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_tr5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrans_rates5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trans_rates5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_5.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5709/1364678826.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(result_file)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtrans_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript_tran\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mtrans_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transformation_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mturn_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mturn_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"transcript_tran\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mn_trans_rates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5709/1008107870.py\u001b[0m in \u001b[0;36mcalculate_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5709/1008107870.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "tran, trans_tr1, trans_rates1, n_trans_rates1 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_1.json\")\n",
    "tran, trans_tr2, trans_rates2, n_trans_rates2 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_2.json\")\n",
    "tran, trans_tr3, trans_rates3, n_trans_rates3 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_3.json\")\n",
    "tran, trans_tr4, trans_rates4, n_trans_rates4 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_4.json\")\n",
    "tran, trans_tr5, trans_rates5, n_trans_rates5 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_5.json\")\n",
    "tran, trans_tr6, trans_rates6, n_trans_rates6 = get_data(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_6.json\")\n",
    "\n",
    "\n",
    "n_valid1 = len([t for t in  n_trans_rates1 if t <0.25])/len(tran)\n",
    "n_valid2 = len([t for t in  n_trans_rates2 if t <0.25])/len(tran)\n",
    "n_valid3 = len([t for t in  n_trans_rates3 if t <0.25])/len(tran)\n",
    "n_valid4 = len([t for t in  n_trans_rates4 if t <0.25])/len(tran)\n",
    "n_valid5 = len([t for t in  n_trans_rates5 if t <0.25])/len(tran)\n",
    "n_valid6 = len([t for t in  n_trans_rates6 if t <0.25])/len(tran)\n",
    "\n",
    "\n",
    "valid1 = len([t for t in  trans_rates1 if t <0.25])/len(tran)\n",
    "valid2 = len([t for t in  trans_rates2 if t <0.25])/len(tran)\n",
    "valid3 = len([t for t in  trans_rates3 if t <0.25])/len(tran)\n",
    "valid4 = len([t for t in  trans_rates4 if t <0.25])/len(tran)\n",
    "valid5 = len([t for t in  trans_rates5 if t <0.25])/len(tran)\n",
    "valid6 = len([t for t in  trans_rates6 if t <0.25])/len(tran)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rewards_1, joint_accs_1, trans_rates_1 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_1.json\")\n",
    "rewards_2, joint_accs_2, trans_rates_2 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_2.json\")\n",
    "rewards_3, joint_accs_3, trans_rates_3 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_3.json\")\n",
    "rewards_4, joint_accs_4, trans_rates_4 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_4.json\")\n",
    "rewards_5, joint_accs_5, trans_rates_5 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_5.json\")\n",
    "rewards_6, joint_accs_6, trans_rates_6 = get_stats(\"/home/altaf/Desktop/RLTest4chatbot/Examples/trade/Results/Evaluation/test_21_Multi_PDQN_6.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ1 = 1-sum(joint_accs_1)/len(joint_accs_1)\n",
    "succ2 = 1-sum(joint_accs_2)/len(joint_accs_2)\n",
    "succ3 = 1-sum(joint_accs_3)/len(joint_accs_3)\n",
    "succ4 = 1-sum(joint_accs_4)/len(joint_accs_4)\n",
    "succ5 = 1-sum(joint_accs_5)/len(joint_accs_5)\n",
    "succ6 = 1-sum(joint_accs_6)/len(joint_accs_6)\n",
    "\n",
    "succ = [succ1, succ2, succ3, succ4, succ5, succ6]\n",
    "\n",
    "\n",
    "tran1 = len([t for t in trans_rates_1 if t<=0.25])/len(trans_rates_1)\n",
    "tran2 = len([t for t in trans_rates_2 if t<=0.25])/len(trans_rates_2)\n",
    "tran3 = len([t for t in trans_rates_3 if t<=0.25])/len(trans_rates_3)\n",
    "tran4 = len([t for t in trans_rates_4 if t<=0.25])/len(trans_rates_4)\n",
    "tran5 = len([t for t in trans_rates_5 if t<=0.25])/len(trans_rates_5)\n",
    "tran6 = len([t for t in trans_rates_6 if t<=0.25])/len(trans_rates_6)\n",
    "\n",
    "\n",
    "trans_rates = len(trans_rates_1)\n",
    "trans =[tran1, tran2, tran3, tran4, tran5, tran6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9273504273504274,\n",
       " 0.6923076923076923,\n",
       " 0.4700854700854701,\n",
       " 0.297008547008547,\n",
       " 0.17735042735042736,\n",
       " 0.1047008547008547]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p1= plt.plot([1,2,3,4,5], succ, label='first plot')\n",
    "plt.plot([1,2,3,4,5],trans, label='Valid transfromation rate')\n",
    "plt.xlabel(\"Top_k\")\n",
    "plt.title(\"RL4Chatbot results on Trade\")\n",
    "\n",
    "plt.savefig('PeaksFile.png')\n",
    "plt.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "x = np.arange(0.1,10.5,0.1) # arbitrary data\n",
    "\n",
    "fg = Figure()\n",
    "ax = fg.gca()\n",
    "ax.plot(succ)\n",
    "\n",
    "ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "fg.savefig(\"example.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "beta  = 0.45\n",
    "benchmark_similarity = 0.8025\n",
    "gamma = 1.8\n",
    "\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "def _disambiguate(sentence):\n",
    "    wsd =[]\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    for word in words : \n",
    "        try :\n",
    "            xx = wordnet.synsets(word)[1]\n",
    "        except :\n",
    "            xx = None\n",
    "        wsd.append((word,xx))\n",
    "    return wsd\n",
    "\n",
    "\n",
    "\n",
    "def calculate_similarity(sentence1, sentence2):\n",
    "    L1 =dict()\n",
    "    L2 =defaultdict(list)\n",
    "    s1_wsd = _disambiguate(sentence1)\n",
    "    s2_wsd = _disambiguate(sentence2)\n",
    "    s1 = [syn  for syn in s1_wsd if syn[1]]\n",
    "    print(s1)\n",
    "    print(s1_wsd)\n",
    "    s2 = [syn  for syn in s2_wsd if syn[1]]\n",
    "    for syn1 in s1:\n",
    "        L1[syn1[0]] =list()\n",
    "        for syn2 in s2:                                     \n",
    "            \n",
    "            subsumer = syn1[1].lowest_common_hypernyms(syn2[1], simulate_root=True)[0]\n",
    "            h =subsumer.max_depth() + 1 # as done on NLTK wordnet        \n",
    "            syn1_dist_subsumer = syn1[1].shortest_path_distance(subsumer,simulate_root =True)\n",
    "            syn2_dist_subsumer = syn2[1].shortest_path_distance(subsumer,simulate_root =True)\n",
    "            l  =syn1_dist_subsumer + syn2_dist_subsumer\n",
    "            f1 = np.exp(-alpha*l)\n",
    "            a  = np.exp(beta*h)\n",
    "            b  = np.exp(-beta*h)\n",
    "            f2 = (a-b) /(a+b)\n",
    "            sim = f1*f2\n",
    "            L1[syn1[0]].append(sim)          \n",
    "            L2[syn2[0]].append(sim)\n",
    "    print(L1.keys())\n",
    "    print(L1)\n",
    "    if L1.keys():\n",
    "\n",
    "        V1 =np.array( [max(L1[key]) for key in L1.keys()])\n",
    "    else:\n",
    "         V1 =[]\n",
    "    return 1\n",
    "\n",
    "    V2 = np.array([max(L2[key]) for key in L2.keys()])\n",
    "\n",
    "    S  = np.linalg.norm(V1)*np.linalg.norm(V2)\n",
    "    C1 = sum(V1>=benchmark_similarity)\n",
    "    C2 = sum(V2>=benchmark_similarity)\n",
    "    Xi = (C1+C2) / gamma\n",
    "\n",
    "    if Xi == 0 :\n",
    "        return 0 \n",
    "    if C1+C2 == 0:\n",
    "            Xi = max(V1.size, V2.size) / 2\n",
    "\n",
    "    return S/Xi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('about', Synset('approximately.r.01')), ('at', Synset('at.n.02'))]\n",
      "[('how', None), ('about', Synset('approximately.r.01')), ('monday', None), ('at', Synset('at.n.02')), ('19:15', None), ('.', None)]\n",
      "dict_keys(['about', 'at'])\n",
      "{'about': [], 'at': []}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5709/4283785608.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5709/508823929.py\u001b[0m in \u001b[0;36mcalculate_similarity\u001b[0;34m(sentence1, sentence2)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m          \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5709/508823929.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mL1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m          \u001b[0mV1\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "s1 = \"how about monday at 19:15.\"\n",
    "s2 = \"htow aqout aqout mmondayat\" \n",
    "\n",
    "\n",
    "print(calculate_similarity(s1,s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8139/2310246799.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dog'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'yu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwup_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "dog = wordnet.synsets('dog')[0] \n",
    "cat =  wordnet.synsets('yu')[0] \n",
    "dog.wup_similarity(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h', 'e', 'e', 'l', 'o']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word1 = \"heelo\"\n",
    "word2 = \"hielo\"\n",
    "l1 = list(word1)\n",
    "l2 = list(word2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DST-testing",
   "language": "python",
   "name": "dst-testing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
